//图像显示
#include<opencv2/opencv.hpp>
using namespace cv;//包含cv命名空间

int main()
{
    Mat src = imread("1.jpg");//载入图像
    imshow("image",src);//显示图像
    waitKey(0);//等待任意键按下
}


//图像腐蚀
#include<opencv2/highgui/highgui.hpp>
#include<opencv2/imgproc/imgproc.hpp>
using namespace cv;
int main()//控制台应用程序的入口函数，我们的程序从这里开始
{
   Mat src = imread("/home/xwfeng/workspace/projects/opencv/read_img/A/1.jpg");//载入原图
   imshow("image1",src);//显示原图
   //进行腐蚀操作
   Mat element = getStructuringElement(MORPH_RECT,Size(15,15));
   Mat dstImage;
   erode(src,dstImage,element);
   //显示效果图
   imshow("image2",dstImage);
   waitKey(0);
   return 0;
}


//图像模糊(均值滤波）
#include<opencv2/highgui/highgui.hpp>
#include<opencv2/imgproc/imgproc.hpp>
using namespace cv;
int main()
{
   Mat src = imread("/home/xwfeng/workspace/projects/opencv/read_img/A/1.jpg");//载入原图
   imshow("image1",src);//显示原图
   //进行均值滤波操作
   Mat dstImage;
   blur(src,dstImage,Size(7,7));
   //显示效果图
   imshow("image2",dstImage);
   waitKey(0);
   
}


//canny边缘检测
#include<opencv2/highgui/highgui.hpp>
#include<opencv2/imgproc/imgproc.hpp>
using namespace cv;
int main()
{
   Mat src = imread("/home/xwfeng/workspace/projects/opencv/read_img/A/1.jpg");//载入原图
   imshow("image1",src);//显示原图
   Mat edge,grayImage;//参数定义
   cvtColor(src,grayImage,CV_BGR2GRAY);//将原图转换为灰度图像
    imshow("image3",grayImage);//显示灰度图像
   blur(grayImage,edge,Size(3,3));//先使用3乘3内核来降噪
   Canny(edge,edge,3,9,3);//运行canny算子
   imshow("image2",edge);
   waitKey(0);
   return 0;
}

//读取并播放视频
#include<opencv2/opencv.hpp>
using namespace cv;//包含cv命名空间
int main()
{
   VideoCapture capture("1.avi");//读入视频
   //循环显示每一帧
   while(1)
  {  Mat frame;//定义一个Mat变量，用于存储每一帧的图像
     capture>>frame;//读取当前帧
     imshow("路径",frame);//显示当前帧
     waitKey(30);//延时30ms
   }
   return 0;
}

//调用摄像头采集图像
#include<opencv2/opencv.hpp>
using namespace cv;//包含cv命名空间
int main()
{
   VideoCapture capture(0);//从摄像头读入视频
   //循环显示每一帧
   while(1)
  {  Mat frame;//定义一个Mat变量，用于存储每一帧的图像
     capture>>frame;//读取当前帧
     imshow("路径",frame);//显示当前帧
     waitKey(30);//延时30ms
   }
   return 0;
}





//角点提取
#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>
#include<opencv2/imgproc/imgproc.hpp>
//添加函数中用到的模块
#include <iostream>

using namespace std;
using namespace cv;
//定义全局变量，与Trackbar相关联的变量声明为全局变量，调用比较方便；
Mat src,src_gray;
int thresh = 150;
int max_thresh = 255;

char* sourceimg = "Source image";
char* cornersimg = "Corners detected";

void Harris_demo(int,void*);

int main(int argc,char* argv[])
{
    src=imread("room.jpg");//读取图像，在当前文件夹下

    cvtColor(src,src_gray,CV_RGB2GRAY);//将图像转换成灰度图

    namedWindow(sourceimg,CV_WINDOW_AUTOSIZE);//一般在创建控制条前，先创建一个窗口用来放置控制条；
    createTrackbar("thresh:",sourceimg,&thresh,max_thresh,Harris_demo);//创建一个控制条，用来改变检测角点的阈值；
    imshow(sourceimg,src);

    Harris_demo(0,0);//调用回调函数；将<span style="font-family: verdana, Arial, helvetica, sans-seriff;">thresh定义为全局变量，不用传递参数；</span>


    waitKey(0);//回车结束
    return 0;
}

void Harris_demo(int,void*)
{
    Mat dst,dst_norm,dst_norm_scaled;

    dst = Mat::zeros(src.size(),CV_32FC1);
    int blocksize = 2;
    int kernel =3;
    double k = 0.04;

    cornerHarris(src_gray,dst,blocksize,kernel,k,4);//进行harris角点检测

    normalize(dst,dst_norm,0,255,NORM_MINMAX,-1,Mat());//对检测的结果进行归一化处理，0到255；
    convertScaleAbs(dst_norm,dst_norm_scaled);//求其绝对值；这个函数会将结果转换成8bit；

    for(int j = 0; j < dst_norm.rows ; j++)
    {
        for(int i = 0; i < dst_norm.cols ; i++)
        {
            if((int) dst_norm.at<float>(j,i) > thresh)//在满足阈值条件的角点处画圆；

            {
                circle(src,Point(i,j),5,Scalar(0,0,255),2,8);
            }
        }
    }
    namedWindow(cornersimg,CV_WINDOW_AUTOSIZE);
    imshow(cornersimg,src);
}


/******************************/
/*        立体匹配和测距        */
/******************************/

#include <opencv2/opencv.hpp>
#include <iostream>

using namespace std;
using namespace cv;

const int imageWidth = 800;                             //摄像头的分辨率
const int imageHeight = 600;
Size imageSize = Size(imageWidth, imageHeight);

Mat rgbImageL, grayImageL;
Mat rgbImageR, grayImageR;
Mat rectifyImageL, rectifyImageR;

Rect validROIL;//图像校正之后，会对图像进行裁剪，这里的validROI就是指裁剪之后的区域
Rect validROIR;

Mat mapLx, mapLy, mapRx, mapRy;     //映射表
Mat Rl, Rr, Pl, Pr, Q;              //校正旋转矩阵R，投影矩阵P 重投影矩阵Q
Mat xyz;              //三维坐标

Point origin;         //鼠标按下的起始点
Rect selection;      //定义矩形选框
bool selectObject = false;    //是否选择对象

int blockSize = 0, uniquenessRatio =0, numDisparities=0;
Ptr<StereoBM> bm = StereoBM::create(16, 9);

/*
事先标定好的相机的参数
fx 0 cx
0 fy cy
0 0  1
*/
Mat cameraMatrixL = (Mat_<double>(3, 3) << 682.55880, 0, 384.13666,
    0, 682.24569, 311.19558,
    0, 0, 1);
Mat distCoeffL = (Mat_<double>(5, 1) << -0.51614, 0.36098, 0.00523, -0.00225, 0.00000);

Mat cameraMatrixR = (Mat_<double>(3, 3) << 685.03817, 0, 397.39092,
    0, 682.54282, 272.04875,
    0, 0, 1);
Mat distCoeffR = (Mat_<double>(5, 1) << -0.46640, 0.22148, 0.00947, -0.00242, 0.00000);

Mat T = (Mat_<double>(3, 1) << -61.34485, 2.89570, -4.76870);//T平移向量
Mat rec = (Mat_<double>(3, 1) << -0.00306, -0.03207, 0.00206);//rec旋转向量
Mat R;//R 旋转矩阵


/*****立体匹配*****/
void stereo_match(int,void*)
{
    bm->setBlockSize(2*blockSize+5);     //SAD窗口大小，5~21之间为宜
    bm->setROI1(validROIL);
    bm->setROI2(validROIR);
    bm->setPreFilterCap(31);
    bm->setMinDisparity(0);  //最小视差，默认值为0, 可以是负值，int型
    bm->setNumDisparities(numDisparities*16+16);//视差窗口，即最大视差值与最小视差值之差,窗口大小必须是16的整数倍，int型
    bm->setTextureThreshold(10);
    bm->setUniquenessRatio(uniquenessRatio);//uniquenessRatio主要可以防止误匹配
    bm->setSpeckleWindowSize(100);
    bm->setSpeckleRange(32);
    bm->setDisp12MaxDiff(-1);
    Mat disp, disp8;
    bm->compute(rectifyImageL, rectifyImageR, disp);//输入图像必须为灰度图
    disp.convertTo(disp8, CV_8U, 255 / ((numDisparities * 16 + 16)*16.));//计算出的视差是CV_16S格式
    reprojectImageTo3D(disp, xyz, Q, true); //在实际求距离时，ReprojectTo3D出来的X / W, Y / W, Z / W都要乘以16(也就是W除以16)，才能得到正确的三维坐标信息。
    xyz = xyz * 16;
    imshow("disparity", disp8);
}

/*****描述：鼠标操作回调*****/
static void onMouse(int event, int x, int y, int, void*)
{
    if (selectObject)
    {
        selection.x = MIN(x, origin.x);
        selection.y = MIN(y, origin.y);
        selection.width = std::abs(x - origin.x);
        selection.height = std::abs(y - origin.y);
    }

    switch (event)
    {
    case EVENT_LBUTTONDOWN:   //鼠标左按钮按下的事件
        origin = Point(x, y);
        selection = Rect(x, y, 0, 0);
        selectObject = true;
        cout << origin <<"in world coordinate is: " << xyz.at<Vec3f>(origin) << endl;
        break;
    case EVENT_LBUTTONUP:    //鼠标左按钮释放的事件
        selectObject = false;
        if (selection.width > 0 && selection.height > 0)
        break;
    }
}


/*****主函数*****/
int main()
{
    /*
    立体校正
    */
    Rodrigues(rec, R); //Rodrigues变换
    stereoRectify(cameraMatrixL, distCoeffL, cameraMatrixR, distCoeffR, imageSize, R, T, Rl, Rr, Pl, Pr, Q, CALIB_ZERO_DISPARITY,
        0, imageSize, &validROIL, &validROIR);
    initUndistortRectifyMap(cameraMatrixL, distCoeffL, Rl, Pr, imageSize, CV_32FC1, mapLx, mapLy);
    initUndistortRectifyMap(cameraMatrixR, distCoeffR, Rr, Pr, imageSize, CV_32FC1, mapRx, mapRy);

    /*
    读取图片
    */
    rgbImageL = imread("left1.jpg", CV_LOAD_IMAGE_COLOR);
    cvtColor(rgbImageL, grayImageL, CV_BGR2GRAY);
    rgbImageR = imread("right1.jpg", CV_LOAD_IMAGE_COLOR);
    cvtColor(rgbImageR, grayImageR, CV_BGR2GRAY);

    imshow("ImageL Before Rectify", grayImageL);
    imshow("ImageR Before Rectify", grayImageR);

    /*
    经过remap之后，左右相机的图像已经共面并且行对准了
    */
    remap(grayImageL, rectifyImageL, mapLx, mapLy, INTER_LINEAR);
    remap(grayImageR, rectifyImageR, mapRx, mapRy, INTER_LINEAR);

    /*
    把校正结果显示出来
    */
    Mat rgbRectifyImageL, rgbRectifyImageR;
    cvtColor(rectifyImageL, rgbRectifyImageL, CV_GRAY2BGR);  //伪彩色图
    cvtColor(rectifyImageR, rgbRectifyImageR, CV_GRAY2BGR);

    //单独显示
    //rectangle(rgbRectifyImageL, validROIL, Scalar(0, 0, 255), 3, 8);
    //rectangle(rgbRectifyImageR, validROIR, Scalar(0, 0, 255), 3, 8);
    imshow("ImageL After Rectify", rgbRectifyImageL);
    imshow("ImageR After Rectify", rgbRectifyImageR);

    //显示在同一张图上
    Mat canvas;
    double sf;
    int w, h;
    sf = 600. / MAX(imageSize.width, imageSize.height);
    w = cvRound(imageSize.width * sf);
    h = cvRound(imageSize.height * sf);
    canvas.create(h, w * 2, CV_8UC3);   //注意通道

    //左图像画到画布上
    Mat canvasPart = canvas(Rect(w * 0, 0, w, h));                                //得到画布的一部分
    resize(rgbRectifyImageL, canvasPart, canvasPart.size(), 0, 0, INTER_AREA);     //把图像缩放到跟canvasPart一样大小
    Rect vroiL(cvRound(validROIL.x*sf), cvRound(validROIL.y*sf),                //获得被截取的区域
        cvRound(validROIL.width*sf), cvRound(validROIL.height*sf));
    //rectangle(canvasPart, vroiL, Scalar(0, 0, 255), 3, 8);                      //画上一个矩形
    cout << "Painted ImageL" << endl;

    //右图像画到画布上
    canvasPart = canvas(Rect(w, 0, w, h));                                      //获得画布的另一部分
    resize(rgbRectifyImageR, canvasPart, canvasPart.size(), 0, 0, INTER_LINEAR);
    Rect vroiR(cvRound(validROIR.x * sf), cvRound(validROIR.y*sf),
        cvRound(validROIR.width * sf), cvRound(validROIR.height * sf));
    //rectangle(canvasPart, vroiR, Scalar(0, 0, 255), 3, 8);
    cout << "Painted ImageR" << endl;

    //画上对应的线条
    for (int i = 0; i < canvas.rows; i += 16)
        line(canvas, Point(0, i), Point(canvas.cols, i), Scalar(0, 255, 0), 1, 8);
    imshow("rectified", canvas);

    /*
    立体匹配
    */
    namedWindow("disparity", CV_WINDOW_AUTOSIZE);
    // 创建SAD窗口 Trackbar
    createTrackbar("BlockSize:\n", "disparity",&blockSize, 8, stereo_match);
    // 创建视差唯一性百分比窗口 Trackbar
    createTrackbar("UniquenessRatio:\n", "disparity", &uniquenessRatio, 50, stereo_match);
    // 创建视差窗口 Trackbar
    createTrackbar("NumDisparities:\n", "disparity", &numDisparities, 16, stereo_match);
    //鼠标响应函数setMouseCallback(窗口名称, 鼠标回调函数, 传给回调函数的参数，一般取0)
    setMouseCallback("disparity", onMouse, 0);
    stereo_match(0,0);

    waitKey(0);
    return 0;
}




#include <opencv2/opencv.hpp>
using namespace std;

int main()
{
    //initialize and allocate memory to load the video stream from camera 
    cv::VideoCapture camera0(1);
    camera0.set(CV_CAP_PROP_FRAME_WIDTH,320);
    camera0.set(CV_CAP_PROP_FRAME_HEIGHT,240);
    cv::VideoCapture camera1(0);
    camera1.set(CV_CAP_PROP_FRAME_WIDTH,320);
    camera1.set(CV_CAP_PROP_FRAME_HEIGHT,240);

    if( !camera0.isOpened() ) return 1;
    if( !camera1.isOpened() ) return 1;

    while(true) {
        //grab and retrieve each frames of the video sequentially 
        cv::Mat3b frame0;
        camera0 >> frame0;
        cv::Mat3b frame1;
        camera1 >> frame1;

        cv::imshow("Video0", frame0);
        cv::imshow("Video1", frame1);
//      std::cout << frame1.rows() << std::endl;
        //wait for 40 milliseconds
        int c = cvWaitKey(40);

        //exit the loop if user press "Esc" key  (ASCII value of "Esc" is 27) 
        if(27 == char(c)) break;
    }

    return 0;
}






